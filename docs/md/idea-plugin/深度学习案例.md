# 深度学习案例 - 数据处理
> 从实战的角度看，模型的设计与开发是个循序渐进的过程，是个不断挖坑填坑的过程。纵然你可能是一个非常资深的算法工程师，也不可能一步到位。

所以，对一个需求有一个大致的概念后，都会先实现一个`baseline`的模型，即使这个模型的效果可能不好。然后我们再从**数据处理、模型设计、训练配置、训练过程、模型评价**等各方面去不断优化以至于提升模型的效果到业务可接受的水平。

## 模型开发的各环节

<center><img src="https://ai-studio-static-online.cdn.bcebos.com/dd8d51f8ae634666934841d7fe797a0cda6c8f0ed4434448aafd2ce6082302ff" width="1000" hegiht="" ></center>
<br></br>

我们可以从纵向首先实现一个baseline的模型，现争取跑通流程，**再着手去一步步的优化**
下面我们以`识别手写数字`作为一个案例去解释模型开发的各个步骤。

## 依赖导入（以paddle为框架）
其实什么框架都一样，无非是优化的好不好，用的方不方便，用的熟不熟悉而已。这里可以选择一个自己最熟悉的框架去试试手
```python
#加载paddle和相关类库
import paddle
from paddle.nn import Linear
import paddle.nn.functional as F
import os
import numpy as np
import matplotlib.pyplot as plt
```
## 数据获取

识别手写数字这个需求，我们首先想到的是需要一大批图片和图片中数字的打标结果，比如：  
>图片：2️⃣（假设我是一个图片:joy:）  
标签：2  

以上是一个我们希望拿到的数据集案例，并且希望数据量越多越好，但毫无疑问的会有以下几个问题：
- 数据从哪里获取：哪里来这么多个图片
- 数据满不满足要求：哪里来这么多个图片还是只有1个数字的
- 数据满不满足要求：哪里来这么多个图片还是同一个大小的，比如5*5
- 标注人员是否足够：就算有了图片，标签需要人去打，哪里来这么多人
- 标准规则是否统一：就算找到这么多人，对同一个2️⃣，万一中间有个叛徒觉得是3，那怎么搞

关于数据获取，在实际开发过程中，**问题包括但不限于以上几个**，这些都是**身先士卒的**产品经理需要去和关联方去battle的

当然了，作为一个资深的大佬，你肯定知道，市面上有诸多现成的数据集可以拿来使用，比如较为出名的**MNIST数据集**

## 数据评估

paddle框架提供了很多数据集的封装，MNIST就是其中之一，可以通过调用直接使用。这就等于打标人员交付了你第一版本的数据集一样，你只知道有数据，但完全不清楚其中质量、样式，所以需要去做一个数据评估

### 调用方法（等于拿到数据）
```python
# 设置数据读取器，API自动读取MNIST数据训练集
train_dataset = paddle.vision.datasets.MNIST(mode='train')
```
### 数据可视化（看看这个数据样式）
```python
# 把数据array化，然后看看她的形状 :tent:
train_data_np = np.array(train_dataset)
print(train_data_np.shape)
```
可以看到打印结果是
(60000, 2)

```python
# 知道形状之后再取一条出来看看
# 内部形状是2，盲猜是一个图片和一个标签，打印一type看看
print(type(train_data_np[0][0]))
print(type(train_data_np[0][1]))
```
结果是

<class 'PIL.Image.Image'>  
<class 'numpy.ndarray'>

这说明是对象和标签的对应关系，其实可以进一步把图片打开看看，可以是可以，但是没必要，这里我就不操作了

但这里，其实我们已经对数据已经评估完毕了，因为数据已经足够完美，不需要再处理了。但实际过程中数据处理往往是非常复杂的
---