# 深度学习案例 - 模型训练
模型训练需要先加载数据，设置学习率，确定优化器（比如梯度下降）等操作。

## 训练参数配置
主要是实现前向计算和反向传播
```python
# 声明网络结构，直接用前面定义的Class MNIST
model = MNIST()

def train(model):
    # 启动训练模式
    model.train()
    # 加载训练集 batch_size 设为 16
    # paddle.vision.datasets.MNIST(mode='train') 这里是paddle自带的数据集，直接拿过来用
    train_loader = paddle.io.DataLoader(paddle.vision.datasets.MNIST(mode='train'), 
                                        batch_size=16, 
                                        shuffle=True)
    # 定义优化器，使用随机梯度下降SGD优化器，学习率设置为0.001
    # model 已经继承了前面nn.layer里的参数，直接拿过来用
    opt = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())
```
## 开始训练

这里采用了二层循环的训练方法，**为什么不是遍历所有训练样本呢？**

这是因为是实际生成研发过程中，数据量通常是非常大的，一次遍历整个数据集可能会导致计算资源消耗过大和训练时间过长，效率很低。
二层嵌套的方式实际上是一种折中，在损失一定精度的前提下提升训练的效率。

这里有两个参数需要设置
- 外层循环：epoch 阶段
- 内层循环：batch 批次  
实际这两个参数的设置是非常讲究的，这里没有绝对的好坏，高手也是不断去试错或者取一个经验值。**太大效率不高，太小精度不高。**

## 归一化
归一化的目的主要是降低计算量，增加效率。  
归一化一般的做法就是将$(X-Min)/Max-Min$，几何意义就是按比例压缩到0-1的区间\或者说将坐标轴放大  
这里的Max就=255（因为像素最大就是255），Min=0  

```python
# 图像归一化函数，将数据范围为[0, 255]的图像归一化到[0, 1]
def norm_img(img):
    # 验证传入数据格式是否正确，img的shape为[batch_size, 28, 28]
    # 这里有个坑，其实这个图像是个灰色图像，按道理来说print出来的shape是2维的，但这里为什么是3呢？是因为在实际计算前会通过paddle.io.DataLoader去加载训练集，这个方法会指定一个batch_size，导致图像的shape是3维的。如果是彩色的，那shape数量就有4个了
    assert len(img.shape) == 3
    batch_size, img_h, img_w = img.shape[0], img.shape[1], img.shape[2]
    # 归一化图像数据
    img = img / 255
    # 将图像形式reshape为[batch_size, 784]
    img = paddle.reshape(img, [batch_size, img_h*img_w])
    
    return img
```
## 开始训练

```python
import paddle
# 确保从paddle.vision.datasets.MNIST中加载的图像数据是np.ndarray类型
paddle.vision.set_image_backend('cv2')

# 声明网络结构
model = MNIST()

def train(model):
    # 启动训练模式
    model.train()
    # 加载训练集 batch_size 设为 16
    train_loader = paddle.io.DataLoader(paddle.vision.datasets.MNIST(mode='train'), 
                                        batch_size=16, 
                                        shuffle=True)
    # 定义优化器，使用随机梯度下降SGD优化器，学习率设置为0.001
    opt = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())
    EPOCH_NUM = 10
    loss_list = []
    for epoch in range(EPOCH_NUM):
        for batch_id, data in enumerate(train_loader()):
            images = norm_img(data[0]).astype('float32')
            labels = data[1].astype('float32')
            
            #前向计算的过程
            predicts = model(images)
            
            #通过方差估计计算损失函数并取平均值
            loss = F.square_error_cost(predicts, labels)
            avg_loss = paddle.mean(loss)
            
            #每训练了1000批次的数据，打印下当前Loss的情况
            if batch_id % 1000 == 0:
                loss = avg_loss.numpy()[0]
                loss_list.append(loss)
                print("epoch_id: {}, batch_id: {}, loss is: {}".format(epoch, batch_id, loss))
            
            #后向传播，更新参数的过程
            avg_loss.backward()
            opt.step()
            opt.clear_grad()
    
    return loss_list
            
loss_list = train(model)
paddle.save(model.state_dict(), './m    nist.pdparams')
```
loss_list中记录了损失函数的变化list，可以print看看最后的loss值从而评估整个模型的效果

